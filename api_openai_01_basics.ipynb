{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBiB3D_izhR6"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "CIKyBpVb0Onj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Generate a list of Top 3 DevOps and Cloud Trends\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "6eym9oAQuqi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "41RLHyMRLZVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"For the given order, return a JSON object\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Order: A pizza and a pepsi\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Output: {'pizza': 1, 'pepsi': 1}\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Order: A burger and 2 sodas\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Output: {'burger': 1, 'soda': 2}\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Order: A burger, A pizza and 2 sodas\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "qD7qGrrB2iGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are Mr Solar System, an expert on Astronomy\\n\\nYou know everything about Solar System\\n\\nRespond in short sentences\\n\\nShape your response as if talking to a 10-years-old\\n\\nYou do NOT anything about topics other than Solar System\\n\\nYou are truthful and never lie. Never make up facts and if you are not 100% sure, reply with why you cannot answer in a truthful way.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What do you know about Pluto?\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Pluto used to be considered the ninth planet in our Solar System, but now it's classified as a dwarf planet. It's very far away from the Sun and it's very cold there. It has a rocky surface and it's smaller than Earth's Moon.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Wasn't Pluto considered a planet earlier?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.24,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "9E1-MyxY0QtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "FgqvgBGG0VjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"Show a globe with students from different parts of the world, each sitting with a laptop. Above them, clouds should be floating, each labeled with a different technology.\",\n",
        "  n=1, #No of images to generate. Must be between 1 and 10.\n",
        "  size=\"1024x1024\" #256x256, 512x512, or 1024x1024\n",
        ")\n",
        "\n",
        "print(response)\n",
        "\n",
        "image_url = response.data[0].url\n",
        "\n",
        "print(image_url)\n"
      ],
      "metadata": {
        "id": "JZpiPj5ussai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "CHXoudGV4QUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_response = client.files.create(\n",
        "  file=open(\"mydata-new-format.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n"
      ],
      "metadata": {
        "id": "ncnebjSp-4Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = upload_response.id"
      ],
      "metadata": {
        "id": "doepw8_153xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WAIT FOR A MINUTE OR SO!\n",
        "fine_tune_response = client.fine_tuning.jobs.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n"
      ],
      "metadata": {
        "id": "mtJtuNvXAqgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_response.id)\n",
        "fine_tune_events.data"
      ],
      "metadata": {
        "id": "QSse4MZ86MMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list(limit=10)"
      ],
      "metadata": {
        "id": "u3cDPVZnCwbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::7zQmdEh7\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a DevOps chatbot.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Which tool allows you to define infrastructure as code?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "E6A4WJ2LF7Pz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}